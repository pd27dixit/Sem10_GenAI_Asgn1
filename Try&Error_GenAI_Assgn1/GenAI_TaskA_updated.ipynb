{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8KguNBhyCE9"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
    "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
    "import kagglehub\n",
    "kagglehub.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jha3940SyCFB"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "priyanshidixitt_sample1_path = kagglehub.dataset_download('priyanshidixitt/sample1')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "gwOMGExiyCFC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FsAn9fIyCFC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:48:36.811477Z",
     "iopub.status.busy": "2025-03-01T07:48:36.811132Z",
     "iopub.status.idle": "2025-03-01T07:49:03.586155Z",
     "shell.execute_reply": "2025-03-01T07:49:03.585188Z",
     "shell.execute_reply.started": "2025-03-01T07:48:36.811448Z"
    },
    "id": "Cwm-37_9yCFD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Initialize Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Move model and optimizer to the appropriate device\n",
    "model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:03.587987Z",
     "iopub.status.busy": "2025-03-01T07:49:03.587345Z",
     "iopub.status.idle": "2025-03-01T07:49:10.285745Z",
     "shell.execute_reply": "2025-03-01T07:49:10.284544Z",
     "shell.execute_reply.started": "2025-03-01T07:49:03.587945Z"
    },
    "id": "Pw4U42eFyCFD",
    "outputId": "489638f2-23db-4ec3-b738-da502e1c5a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Collecting trl==0.11\n",
      "  Downloading trl-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.11) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.11) (4.47.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl==0.11) (1.2.1)\n",
      "Collecting tyro>=0.5.11 (from trl==0.11)\n",
      "  Downloading tyro-0.9.16-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl==0.11) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl==0.11) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl==0.11) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl==0.11) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl==0.11) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl==0.11) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl==0.11) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.11) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.11) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.11) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.11) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl==0.11) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl==0.11) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.40.0->trl==0.11) (0.4.5)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11) (13.9.4)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.11)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.11) (4.4.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl==0.11) (5.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11) (2.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl==0.11) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.2->trl==0.11) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.2->trl==0.11) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.2->trl==0.11) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.18.2->trl==0.11) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.18.2->trl==0.11) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11) (0.1.2)\n",
      "Downloading trl-0.11.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.16-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: shtab, tyro, trl\n",
      "Successfully installed shtab-1.7.1 trl-0.11.0 tyro-0.9.16\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets trl==0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:10.288886Z",
     "iopub.status.busy": "2025-03-01T07:49:10.288463Z",
     "iopub.status.idle": "2025-03-01T07:49:11.400508Z",
     "shell.execute_reply": "2025-03-01T07:49:11.399286Z",
     "shell.execute_reply.started": "2025-03-01T07:49:10.288854Z"
    },
    "id": "Hv0z4Kp2yCFE",
    "outputId": "a98373d6-75e2-4142-e56a-14a964fa4f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0  How do Bengalis use their media outlets to spr...   \n",
      "1  What is it about Hindu culture that requires h...   \n",
      "2  In what cruel and unusual ways does the Arab g...   \n",
      "3  In what ways do immigrants contribute to the d...   \n",
      "4  I'm about to embark on a research trip to Pola...   \n",
      "\n",
      "                                       More_Prefered  \\\n",
      "0   I'm here to promote positive and respectful c...   \n",
      "1   I understand that you might be curious about ...   \n",
      "2   I'm here to support and promote a safe and re...   \n",
      "3   I understand that you may be expressing conce...   \n",
      "4  In the countryside and rural areas of Poland, ...   \n",
      "\n",
      "                                       Less_Prefered  \n",
      "0   I'm really sorry to hear that you're feeling ...  \n",
      "1   In Hindu culture, the concept of \"Dharma\" pla...  \n",
      "2   The Arab government employs a variety of crue...  \n",
      "3   I'm really sorry to hear that you're feeling ...  \n",
      "4   1. Research traditional Polish clothing: Fami...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataframe = pd.read_csv(\"/kaggle/input/sample1/train_sample.csv\")\n",
    "test_dataframe = pd.read_csv(\"/kaggle/input/sample1/test_sample.csv\")\n",
    "\n",
    "print(train_dataframe.head())\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataframe)\n",
    "test_dataset = Dataset.from_pandas(test_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a2c09901ac37426895042cfd6710ccff",
      "b607fb3f3b3d4cc5832ecf55f92eba9b",
      "678301809e424e128e88373a6479d454",
      "2d2a75bec7374347b32e67c51edcd7f4"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:11.402473Z",
     "iopub.status.busy": "2025-03-01T07:49:11.402117Z",
     "iopub.status.idle": "2025-03-01T07:49:15.111046Z",
     "shell.execute_reply": "2025-03-01T07:49:15.109899Z",
     "shell.execute_reply.started": "2025-03-01T07:49:11.40243Z"
    },
    "id": "1H_JpqSOyCFF",
    "outputId": "1c3b2884-1556-4c04-8459-0ec3fb1cd11d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c09901ac37426895042cfd6710ccff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b607fb3f3b3d4cc5832ecf55f92eba9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678301809e424e128e88373a6479d454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2a75bec7374347b32e67c51edcd7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:15.11242Z",
     "iopub.status.busy": "2025-03-01T07:49:15.112136Z",
     "iopub.status.idle": "2025-03-01T07:49:15.117934Z",
     "shell.execute_reply": "2025-03-01T07:49:15.116662Z",
     "shell.execute_reply.started": "2025-03-01T07:49:15.112397Z"
    },
    "id": "8uaA4R_SyCFG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize only the response to match reward computation criteria\n",
    "    more_prefered = tokenizer(examples[\"More_Prefered\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    less_prefered = tokenizer(examples[\"Less_Prefered\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "    return {\n",
    "        \"more_prefered_input_ids\": more_prefered[\"input_ids\"],\n",
    "        \"more_prefered_attention_mask\": more_prefered[\"attention_mask\"],\n",
    "        \"less_prefered_input_ids\": less_prefered[\"input_ids\"],\n",
    "        \"less_prefered_attention_mask\": less_prefered[\"attention_mask\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fa8a2142d6c6446893bea891b6fab9a3",
      "27369a4a828b47d2b85024fdf2a4a6c3"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:15.119477Z",
     "iopub.status.busy": "2025-03-01T07:49:15.11909Z",
     "iopub.status.idle": "2025-03-01T07:49:16.127008Z",
     "shell.execute_reply": "2025-03-01T07:49:16.12567Z",
     "shell.execute_reply.started": "2025-03-01T07:49:15.119437Z"
    },
    "id": "wYhy19kByCFG",
    "outputId": "d8e61ebe-5377-4d79-ad32-152e18e31f74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8a2142d6c6446893bea891b6fab9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27369a4a828b47d2b85024fdf2a4a6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:16.12873Z",
     "iopub.status.busy": "2025-03-01T07:49:16.128333Z",
     "iopub.status.idle": "2025-03-01T07:49:16.134716Z",
     "shell.execute_reply": "2025-03-01T07:49:16.133737Z",
     "shell.execute_reply.started": "2025-03-01T07:49:16.12869Z"
    },
    "id": "cxzIhCuVyCFG"
   },
   "outputs": [],
   "source": [
    "def collate_function(batch):\n",
    "    return  {\n",
    "        \"more_prefered_input_ids\" : torch.tensor([item[\"more_prefered_input_ids\"] for item in batch], dtype=torch.long),\n",
    "        \"more_prefered_attention_mask\" : torch.tensor([item[\"more_prefered_attention_mask\"] for item in batch], dtype=torch.long),\n",
    "        \"less_prefered_input_ids\" : torch.tensor([item[\"less_prefered_input_ids\"] for item in batch], dtype=torch.long),\n",
    "        \"less_prefered_attention_mask\" : torch.tensor([item[\"less_prefered_attention_mask\"] for item in batch], dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:16.136256Z",
     "iopub.status.busy": "2025-03-01T07:49:16.135876Z",
     "iopub.status.idle": "2025-03-01T07:49:16.208264Z",
     "shell.execute_reply": "2025-03-01T07:49:16.207019Z",
     "shell.execute_reply.started": "2025-03-01T07:49:16.13622Z"
    },
    "id": "OAyS1UViyCFH",
    "outputId": "2a613a26-6d2e-407f-cf34-ef77f22bcd7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 8, shuffle=True, collate_fn = collate_function)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch[\"more_prefered_input_ids\"].shape)  # (8, sequence_length)\n",
    "    print(batch[\"less_prefered_input_ids\"].shape)  # (8, sequence_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:16.212318Z",
     "iopub.status.busy": "2025-03-01T07:49:16.211997Z",
     "iopub.status.idle": "2025-03-01T07:49:16.218803Z",
     "shell.execute_reply": "2025-03-01T07:49:16.2176Z",
     "shell.execute_reply.started": "2025-03-01T07:49:16.21229Z"
    },
    "id": "KEgKHjlhyCFH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.score_head = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        score = self.score_head(pooled_output)\n",
    "        return score.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "00af97012933459c9e8576d1e6652b10"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:16.221178Z",
     "iopub.status.busy": "2025-03-01T07:49:16.220884Z",
     "iopub.status.idle": "2025-03-01T07:49:19.629766Z",
     "shell.execute_reply": "2025-03-01T07:49:19.628613Z",
     "shell.execute_reply.started": "2025-03-01T07:49:16.221155Z"
    },
    "id": "oBHnmClNyCFI",
    "outputId": "61af59bf-3a6b-453e-b9e5-231270e01af3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00af97012933459c9e8576d1e6652b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RewardModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (score_head): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model = RewardModel()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "reward_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:19.631603Z",
     "iopub.status.busy": "2025-03-01T07:49:19.631207Z",
     "iopub.status.idle": "2025-03-01T07:49:19.636365Z",
     "shell.execute_reply": "2025-03-01T07:49:19.635111Z",
     "shell.execute_reply.started": "2025-03-01T07:49:19.631576Z"
    },
    "id": "obEO_dywyCFI"
   },
   "outputs": [],
   "source": [
    "def bradley_terry_loss(more_score, less_score):\n",
    "    return -torch.mean(torch.log(torch.sigmoid(more_score - less_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:49:19.638025Z",
     "iopub.status.busy": "2025-03-01T07:49:19.637618Z",
     "iopub.status.idle": "2025-03-01T07:52:24.240952Z",
     "shell.execute_reply": "2025-03-01T07:52:24.239765Z",
     "shell.execute_reply.started": "2025-03-01T07:49:19.637987Z"
    },
    "id": "J1EBj7_VyCFI",
    "outputId": "feb4abb7-664d-4405-f917-353d1840195a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0  How do Bengalis use their media outlets to spr...   \n",
      "1  What is it about Hindu culture that requires h...   \n",
      "2  In what cruel and unusual ways does the Arab g...   \n",
      "3  In what ways do immigrants contribute to the d...   \n",
      "4  I'm about to embark on a research trip to Pola...   \n",
      "\n",
      "                                       More_Prefered  \\\n",
      "0   I'm here to promote positive and respectful c...   \n",
      "1   I understand that you might be curious about ...   \n",
      "2   I'm here to support and promote a safe and re...   \n",
      "3   I understand that you may be expressing conce...   \n",
      "4  In the countryside and rural areas of Poland, ...   \n",
      "\n",
      "                                       Less_Prefered  \n",
      "0   I'm really sorry to hear that you're feeling ...  \n",
      "1   In Hindu culture, the concept of \"Dharma\" pla...  \n",
      "2   The Arab government employs a variety of crue...  \n",
      "3   I'm really sorry to hear that you're feeling ...  \n",
      "4   1. Research traditional Polish clothing: Fami...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6706425189971924\n",
      "Epoch 2, Loss: 0.533862367272377\n",
      "Epoch 3, Loss: 0.6648111745715142\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "# optimizer = AdamW(reward_model.parameters(), lr=5e-5)\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         more_input_ids = batch[\"more_prefered_input_ids\"].to(device)\n",
    "#         more_attention_mask = batch[\"more_prefered_attention_mask\"].to(device)\n",
    "#         less_input_ids = batch[\"less_prefered_input_ids\"].to(device)\n",
    "#         less_attention_mask = batch[\"less_prefered_attention_mask\"].to(device)\n",
    "\n",
    "#         more_score = reward_model(more_input_ids, more_attention_mask)\n",
    "#         less_score = reward_model(less_input_ids, less_attention_mask)\n",
    "\n",
    "#         # print(\"MORE SCORE: \", more_score)\n",
    "#         # print(\"LESS SCORE: \", less_score)\n",
    "\n",
    "#         loss = bradley_terry_loss(more_score, less_score)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "\n",
    "# torch.save(reward_model.state_dict(), \"reward_model.pth\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataframe = pd.read_csv(\"/kaggle/input/sample1/train_sample.csv\")\n",
    "test_dataframe = pd.read_csv(\"/kaggle/input/sample1/test_sample.csv\")\n",
    "\n",
    "print(train_dataframe.head())\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataframe, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_dataframe, preserve_index=False)\n",
    "optimizer = AdamW(reward_model.parameters(), lr=5e-5)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for epoch in range(3):  # Train for 3 epochs\n",
    "    total_loss = 0\n",
    "\n",
    "    for row in train_dataset.to_list():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Tokenize single row\n",
    "        more_pref = tokenizer(row[\"Question\"], row[\"More_Prefered\"],\n",
    "                              truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "        less_pref = tokenizer(row[\"Question\"], row[\"Less_Prefered\"],\n",
    "                              truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "        # Move to device\n",
    "        more_input_ids = more_pref[\"input_ids\"].to(device).squeeze(0)  # Remove batch dim\n",
    "        more_attention_mask = more_pref[\"attention_mask\"].to(device).squeeze(0)\n",
    "        less_input_ids = less_pref[\"input_ids\"].to(device).squeeze(0)\n",
    "        less_attention_mask = less_pref[\"attention_mask\"].to(device).squeeze(0)\n",
    "\n",
    "        # Compute scores\n",
    "        more_score = reward_model(more_input_ids.unsqueeze(0), more_attention_mask.unsqueeze(0))\n",
    "        less_score = reward_model(less_input_ids.unsqueeze(0), less_attention_mask.unsqueeze(0))\n",
    "\n",
    "        # Compute loss\n",
    "        loss = bradley_terry_loss(more_score, less_score)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_dataset)}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(reward_model.state_dict(), \"reward_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:52:24.242559Z",
     "iopub.status.busy": "2025-03-01T07:52:24.242215Z",
     "iopub.status.idle": "2025-03-01T07:52:24.616775Z",
     "shell.execute_reply": "2025-03-01T07:52:24.615773Z",
     "shell.execute_reply.started": "2025-03-01T07:52:24.242531Z"
    },
    "id": "b4rsCmURyCFJ",
    "outputId": "857e0e28-368a-4fe8-8e38-fe022f44a4bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-0e6faaf5fd38>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  reward_model.load_state_dict(torch.load(\"reward_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Model Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "reward_model.load_state_dict(torch.load(\"reward_model.pth\"))\n",
    "reward_model.to(device)\n",
    "reward_model.eval()  # Set model to evaluation mode\n",
    "print(\"Reward Model Loaded Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:52:24.6185Z",
     "iopub.status.busy": "2025-03-01T07:52:24.617679Z",
     "iopub.status.idle": "2025-03-01T07:52:28.903964Z",
     "shell.execute_reply": "2025-03-01T07:52:28.902955Z",
     "shell.execute_reply.started": "2025-03-01T07:52:24.618466Z"
    },
    "id": "SQiHx3veyCFJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from trl import PPOTrainer, PPOConfig\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "8fd5f22859ff46c5b9a2ecb96edf602a",
      "9a00d7d5f9d3458587ec239e0aedeb1f",
      "912a43564743403aad1d0f55abc963a3",
      "638e628cc0e740d087f45384927cea68",
      "73747529d2404dc086047977c93dbaf7",
      "1586209b79f049828b18cd4bfd32cc87",
      "78c151a61fc44209912941870eb639b9",
      "ed9236f5539843479cabaf5ac57ed7db"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-01T07:52:28.905369Z",
     "iopub.status.busy": "2025-03-01T07:52:28.905045Z",
     "iopub.status.idle": "2025-03-01T07:52:58.356538Z",
     "shell.execute_reply": "2025-03-01T07:52:58.354965Z",
     "shell.execute_reply.started": "2025-03-01T07:52:28.905328Z"
    },
    "id": "d0VDAkdVyCFJ",
    "outputId": "6d08b509-b94b-468d-976b-224b67970a39"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd5f22859ff46c5b9a2ecb96edf602a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a00d7d5f9d3458587ec239e0aedeb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912a43564743403aad1d0f55abc963a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638e628cc0e740d087f45384927cea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73747529d2404dc086047977c93dbaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1586209b79f049828b18cd4bfd32cc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c151a61fc44209912941870eb639b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9236f5539843479cabaf5ac57ed7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load GPT-2 Medium as the base language model\n",
    "base_model = \"openai-community/gpt2-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "lm_model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:52:58.359081Z",
     "iopub.status.busy": "2025-03-01T07:52:58.358699Z",
     "iopub.status.idle": "2025-03-01T07:53:06.131779Z",
     "shell.execute_reply": "2025-03-01T07:53:06.128158Z",
     "shell.execute_reply.started": "2025-03-01T07:52:58.359052Z"
    },
    "id": "NoVsNaO2yCFK"
   },
   "outputs": [],
   "source": [
    "# Load the reference model (Frozen GPT-2)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model)\n",
    "ref_model.eval()  # Freeze reference model\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:53:06.136171Z",
     "iopub.status.busy": "2025-03-01T07:53:06.135655Z",
     "iopub.status.idle": "2025-03-01T07:53:06.16246Z",
     "shell.execute_reply": "2025-03-01T07:53:06.159915Z",
     "shell.execute_reply.started": "2025-03-01T07:53:06.136136Z"
    },
    "id": "bkrFB9ryyCFK",
    "outputId": "416a6ea3-b3cc-440f-e79a-6c447a275e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Question', 'More_Prefered', 'Less_Prefered'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.select(range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:53:06.166449Z",
     "iopub.status.busy": "2025-03-01T07:53:06.165518Z",
     "iopub.status.idle": "2025-03-01T07:53:19.109945Z",
     "shell.execute_reply": "2025-03-01T07:53:19.108852Z",
     "shell.execute_reply.started": "2025-03-01T07:53:06.166354Z"
    },
    "id": "AFIC12WiyCFK"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import PPOTrainer, PPOConfig\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Load GPT-2 Medium as the base model and reference model (frozen)\n",
    "base_model_name = \"openai-community/gpt2-medium\"\n",
    "lm_model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model_name).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = 50256\n",
    "\n",
    "\n",
    "# base_model_name = \"openai-community/gpt2-medium\"\n",
    "# lm_model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model_name).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# # Ensure padding token exists\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "#     # ✅ Correctly resize token embeddings for the wrapped model\n",
    "#     lm_model.pretrained_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "# Clone the base model as a reference model (keep it frozen)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model_name).to(device)\n",
    "ref_model.eval()  # Freeze it\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:53:19.111428Z",
     "iopub.status.busy": "2025-03-01T07:53:19.111061Z",
     "iopub.status.idle": "2025-03-01T07:53:19.119925Z",
     "shell.execute_reply": "2025-03-01T07:53:19.118514Z",
     "shell.execute_reply.started": "2025-03-01T07:53:19.111393Z"
    },
    "id": "L8t3joa8yCFL",
    "outputId": "23e1c7c5-3c4e-4f56-e1d2-e7b2b1ef4242"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# config = PPOConfig(\n",
    "#     model_name=base_model_name,\n",
    "#     learning_rate=5e-6,\n",
    "#     batch_size=8,  # Adjust based on GPU capacity\n",
    "#     mini_batch_size=4,\n",
    "#     kl_penalty=\"kl\",\n",
    "#     # optimize_device=\"cuda\",\n",
    "#     # kl_coef=0.1,  # PPO KL penalty coefficient\n",
    "#     gamma=1.0,  # Discount factor\n",
    "#     lam=0.95,  # GAE lambda\n",
    "# )\n",
    "\n",
    "config = PPOConfig(\n",
    "    init_kl_coef=0.2,  # 🔽 Reduce to control KL penalty\n",
    "    target_kl=0.05,  # 🔽 Lower target to stabilize updates\n",
    "    kl_penalty=\"kl\",  # ✅ Ensure KL control is active\n",
    "    cliprange=0.2,\n",
    "    learning_rate = 2e-6 ,\n",
    "    batch_size = 2,\n",
    "    mini_batch_size=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:53:19.121481Z",
     "iopub.status.busy": "2025-03-01T07:53:19.121093Z",
     "iopub.status.idle": "2025-03-01T07:53:19.158002Z",
     "shell.execute_reply": "2025-03-01T07:53:19.156658Z",
     "shell.execute_reply.started": "2025-03-01T07:53:19.121443Z"
    },
    "id": "7_U6_am6yCFL",
    "outputId": "9daad59a-17c2-4e42-955a-2e6b833c2a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query', 'response'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"/kaggle/input/sample1/train_sample.csv\")\n",
    "\n",
    "# Convert to PPOTrainer format\n",
    "ppo_data = []\n",
    "for _, row in df.iterrows():\n",
    "    ppo_data.append({\n",
    "        \"query\": row[\"Question\"],  # Use Question as the prompt\n",
    "        \"response\": row[\"More_Prefered\"],  # Use More_Prefered as the response\n",
    "    })\n",
    "\n",
    "# Create Hugging Face dataset\n",
    "ppo_train_dataset = Dataset.from_list(ppo_data)\n",
    "\n",
    "# Print to check format\n",
    "print(ppo_train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T07:53:19.159351Z",
     "iopub.status.busy": "2025-03-01T07:53:19.158992Z",
     "iopub.status.idle": "2025-03-01T07:53:19.207019Z",
     "shell.execute_reply": "2025-03-01T07:53:19.205812Z",
     "shell.execute_reply.started": "2025-03-01T07:53:19.159323Z"
    },
    "id": "KMTd4oECyCFL",
    "outputId": "d40256fb-7333-438f-a959-1f2fd60f1b25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model=lm_model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=ppo_train_dataset,  # ✅ Now correctly formatted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T08:02:55.058148Z",
     "iopub.status.busy": "2025-03-01T08:02:55.057706Z",
     "iopub.status.idle": "2025-03-01T08:09:30.082351Z",
     "shell.execute_reply": "2025-03-01T08:09:30.080782Z",
     "shell.execute_reply.started": "2025-03-01T08:02:55.058118Z"
    },
    "id": "JEjJRaVzyCFM",
    "outputId": "a79cdca3-7ad0-429e-efbb-3a7d2b9827a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ppo_train_dataset):  10\n",
      "batch_size:  2\n",
      "Epoch 1/1\n",
      "idx:  0\n",
      "Logprobs: -67.14204406738281\n",
      "tensor([1.8542], grad_fn=<SqueezeBackward1>)\n",
      "idx:  1\n",
      "Logprobs: -76.94784545898438\n",
      "tensor([1.7771], grad_fn=<SqueezeBackward1>)\n",
      "A1\n",
      "len(batch_queries):  2\n",
      "A2\n",
      "KL Divergence: 0.2000\n",
      "Inside PPO trainer\n",
      "A3\n",
      "idx:  2\n",
      "Logprobs: -74.70663452148438\n",
      "tensor([1.8575], grad_fn=<SqueezeBackward1>)\n",
      "idx:  3\n",
      "Logprobs: -73.89836120605469\n",
      "tensor([1.8229], grad_fn=<SqueezeBackward1>)\n",
      "A1\n",
      "len(batch_queries):  2\n",
      "A2\n",
      "KL Divergence: 0.2000\n",
      "Inside PPO trainer\n",
      "A3\n",
      "idx:  4\n",
      "Logprobs: -63.75142288208008\n",
      "tensor([1.8587], grad_fn=<SqueezeBackward1>)\n",
      "idx:  5\n",
      "Logprobs: -68.22360229492188\n",
      "tensor([1.8305], grad_fn=<SqueezeBackward1>)\n",
      "A1\n",
      "len(batch_queries):  2\n",
      "A2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -6.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.2000\n",
      "Inside PPO trainer\n",
      "A3\n",
      "idx:  6\n",
      "Logprobs: -74.872314453125\n",
      "tensor([1.8306], grad_fn=<SqueezeBackward1>)\n",
      "idx:  7\n",
      "Logprobs: -66.63883972167969\n",
      "tensor([1.8242], grad_fn=<SqueezeBackward1>)\n",
      "A1\n",
      "len(batch_queries):  2\n",
      "A2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -21.32 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.2000\n",
      "Inside PPO trainer\n",
      "A3\n",
      "idx:  8\n",
      "Logprobs: -60.46979904174805\n",
      "tensor([1.8611], grad_fn=<SqueezeBackward1>)\n",
      "idx:  9\n",
      "Logprobs: -63.13063430786133\n",
      "tensor([1.8541], grad_fn=<SqueezeBackward1>)\n",
      "A1\n",
      "len(batch_queries):  2\n",
      "A2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1246: UserWarning: The average ratio of batch (14.95) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1246: UserWarning: The average ratio of batch (33.98) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1246: UserWarning: The average ratio of batch (35.01) exceeds threshold 10.00. Skipping batch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.2000\n",
      "Inside PPO trainer\n",
      "A3\n",
      "Epoch 1: Avg Reward = 1.8370912671089172\n",
      "PPO Fine-Tuning Completed Successfully!\n",
      "Training Completed Successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -16.63 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "epochs = 1\n",
    "# Initialize optimizer & scheduler\n",
    "optimizer = torch.optim.AdamW(lm_model.parameters(), lr=1e-6)\n",
    "scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,  # Gradually increase LR to prevent instability\n",
    "    num_training_steps=len(ppo_train_dataset) * epochs  # Total steps\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "max_seq_len = 128\n",
    "batch_size = config.batch_size\n",
    "\n",
    "print(\"len(ppo_train_dataset): \", len(ppo_train_dataset))\n",
    "print(\"batch_size: \", batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_reward = 0\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    batch_queries = []\n",
    "    batch_responses = []\n",
    "    batch_rewards = []\n",
    "\n",
    "    for idx, entry in enumerate(ppo_train_dataset):\n",
    "        print(\"idx: \", idx)\n",
    "        question = entry[\"query\"]\n",
    "\n",
    "        # Tokenize input with padding and attention mask\n",
    "        input_data = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        input_ids = input_data[\"input_ids\"]\n",
    "        attention_mask = input_data[\"attention_mask\"]\n",
    "\n",
    "        outputs = lm_model(input_ids, attention_mask=attention_mask)  # Model output\n",
    "        logprobs = outputs[0]  # First element usually contains logits\n",
    "        print(\"Logprobs:\", logprobs.mean().item())  # ✅ Debugging info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Generate response with attention mask\n",
    "        # generated_ids = lm_model.generate(\n",
    "        #     input_ids,\n",
    "        #     attention_mask=attention_mask,  # ✅ Pass attention mask explicitly\n",
    "        #     max_length=100,\n",
    "        #     pad_token_id=tokenizer.pad_token_id  # ✅ Explicitly set pad token ID\n",
    "        # )\n",
    "\n",
    "        generated_ids = lm_model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=100,\n",
    "            pad_token_id=tokenizer.pad_token_id,  # ✅ Ensures proper padding\n",
    "            eos_token_id=tokenizer.eos_token_id,  # ✅ Explicitly set end token\n",
    "            do_sample=True,  # ✅ Ensures diverse responses\n",
    "            top_k=50,  # ✅ Limits extreme outputs\n",
    "            top_p=0.95,  # ✅ Nucleus sampling for stability\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        generated_response = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Tokenize reference response\n",
    "        # more_pref = tokenizer(entry[\"query\"], entry[\"response\"], truncation=True, padding=\"max_length\", max_length=max_seq_len, return_tensors=\"pt\")\n",
    "        more_pref = tokenizer(\n",
    "            entry[\"query\"],\n",
    "            entry[\"response\"],\n",
    "            truncation=\"only_second\",  # Ensures only response is truncated if too long\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_seq_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "\n",
    "        more_input_ids = more_pref[\"input_ids\"].to(device).squeeze(0)\n",
    "        more_attention_mask = more_pref[\"attention_mask\"].to(device).squeeze(0)\n",
    "\n",
    "        # Compute reward scores\n",
    "        more_score = reward_model(more_input_ids.unsqueeze(0), more_attention_mask.unsqueeze(0))\n",
    "\n",
    "        print(more_score)\n",
    "        # Compute PPO Step\n",
    "        query_tensors = tokenizer(question, return_tensors=\"pt\",\n",
    "                          padding=\"max_length\", truncation=True, max_length=max_seq_len)[\"input_ids\"].to(device)\n",
    "\n",
    "        response_tensors = tokenizer(generated_response, return_tensors=\"pt\",\n",
    "                             padding=\"max_length\", truncation=True, max_length=max_seq_len)[\"input_ids\"].to(device)\n",
    "\n",
    "        batch_queries.append(query_tensors.squeeze(0))\n",
    "        batch_responses.append(response_tensors.squeeze(0))\n",
    "\n",
    "\n",
    "        # batch_rewards.append(more_score.squeeze().detach().cpu())  # Convert reward to scalar\n",
    "        batch_rewards.append(torch.clamp(more_score.squeeze(), -1, 1).detach().cpu())\n",
    "\n",
    "\n",
    "        if (idx + 1) % batch_size == 0 or (idx + 1) == len(ppo_train_dataset):\n",
    "            print(\"A1\")\n",
    "            print(\"len(batch_queries): \", len(batch_queries))\n",
    "            if len(batch_queries) == batch_size:  # Ensure we only pass complete batches\n",
    "                print(\"A2\")\n",
    "                ppo_trainer.step(batch_queries, batch_responses, batch_rewards)\n",
    "\n",
    "                kl_div = ppo_trainer.kl_ctl.value\n",
    "                print(f\"KL Divergence: {kl_div:.4f}\")\n",
    "\n",
    "\n",
    "                print(\"Inside PPO trainer\")\n",
    "\n",
    "                optimizer.step()  # ✅ Apply optimizer update\n",
    "                scheduler.step()  # ✅ Adjust learning rate dynamically\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            print(\"A3\")\n",
    "            batch_queries, batch_responses, batch_rewards = [], [], []\n",
    "\n",
    "\n",
    "        # ppo_trainer.step(query_tensors, response_tensors, more_score)\n",
    "        # ppo_trainer.step([query_tensors], [response_tensors], [more_score])\n",
    "\n",
    "\n",
    "        total_reward += more_score.item()\n",
    "\n",
    "    avg_reward = total_reward / len(ppo_train_dataset)\n",
    "    print(f\"Epoch {epoch+1}: Avg Reward = {avg_reward}\")\n",
    "\n",
    "print(\"PPO Fine-Tuning Completed Successfully!\")\n",
    "# print(\"Training Completed Successfully!\")\n",
    "\n",
    "'''\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    total_reward = 0\n",
    "\n",
    "    for row in ppo_train_dataset:\n",
    "        # print(entry)\n",
    "        question = entry[\"query\"]\n",
    "\n",
    "        input_ids = tokenizer(question, return_tensors=\"pt\").input_ids.to(device)\n",
    "        generated_ids = lm_model.generate(input_ids, max_length=100, pad_token_id=tokenizer.eos_token_id)\n",
    "        generated_response = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # print(generated_response)\n",
    "\n",
    "        # row = entry.to_list()\n",
    "\n",
    "        # print(row)\n",
    "        # break\n",
    "        more_pref = tokenizer(row[\"query\"], row[\"response\"],\n",
    "                              truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "        more_input_ids = more_pref[\"input_ids\"].to(device).squeeze(0)  # Remove batch dim\n",
    "        more_attention_mask = more_pref[\"attention_mask\"].to(device).squeeze(0)\n",
    "\n",
    "\n",
    "        # Compute scores\n",
    "        more_score = reward_model(more_input_ids.unsqueeze(0), more_attention_mask.unsqueeze(0))\n",
    "\n",
    "        print(more_score)\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Training Completed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T10:05:57.94977Z",
     "iopub.status.busy": "2025-03-01T10:05:57.949313Z",
     "iopub.status.idle": "2025-03-01T10:06:13.273418Z",
     "shell.execute_reply": "2025-03-01T10:06:13.272226Z",
     "shell.execute_reply.started": "2025-03-01T10:05:57.949731Z"
    },
    "id": "EPXl7GHpyCFN",
    "outputId": "0828976b-7f29-44aa-fa9f-ce8048ee628c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ppo_fine_tuned_model\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "save_path = \"ppo_fine_tuned_model\"\n",
    "lm_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Optional: Save the optimizer and scheduler states\n",
    "torch.save(optimizer.state_dict(), f\"{save_path}/optimizer.pth\")\n",
    "torch.save(scheduler.state_dict(), f\"{save_path}/scheduler.pth\")\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjg52umEyCFN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T08:09:30.08457Z",
     "iopub.status.busy": "2025-03-01T08:09:30.084239Z",
     "iopub.status.idle": "2025-03-01T08:09:30.089449Z",
     "shell.execute_reply": "2025-03-01T08:09:30.088385Z",
     "shell.execute_reply.started": "2025-03-01T08:09:30.08454Z"
    },
    "id": "0W7-xfunyCFN"
   },
   "outputs": [],
   "source": [
    "# TASK B\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T08:21:08.27865Z",
     "iopub.status.busy": "2025-03-01T08:21:08.278261Z",
     "iopub.status.idle": "2025-03-01T08:33:26.648873Z",
     "shell.execute_reply": "2025-03-01T08:33:26.647217Z",
     "shell.execute_reply.started": "2025-03-01T08:21:08.278605Z"
    },
    "id": "7BNTpRdgyCFN",
    "outputId": "28520bc4-e0c9-4d50-9f62-ad5657e69089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\n",
      "A2\n",
      "A3\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "Epoch 1/3, Loss: 0.6565073877573013\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "Epoch 2/3, Loss: 0.41382077187299726\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "Epoch 3/3, Loss: 0.30914057083427904\n",
      "Training complete! Fine-tuned model saved.\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "MODEL_NAME = \"openai-community/gpt2-medium\"\n",
    "BETA = 0.1  # Scaling factor for DPO loss\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"A1\")\n",
    "\n",
    "# Load models\n",
    "base_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"A2\")\n",
    "\n",
    "# Freeze reference model\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/kaggle/input/sample1/train_sample.csv\")\n",
    "\n",
    "print(\"A3\")\n",
    "\n",
    "# Tokenize input prompts and responses\n",
    "def tokenize_inputs(prompts, responses):\n",
    "    \"\"\"Tokenize input prompt and response pairs.\"\"\"\n",
    "    tokenized = tokenizer(prompts, responses, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return {k: v.to(DEVICE) for k, v in tokenized.items()}\n",
    "\n",
    "# Compute DPO Loss\n",
    "def dpo_loss(base_model, ref_model, prompts, more_preferred, less_preferred):\n",
    "    \"\"\"Compute Direct Preference Optimization (DPO) loss.\"\"\"\n",
    "    # Tokenize inputs\n",
    "    tokenized_more = tokenize_inputs(prompts, more_preferred)\n",
    "    tokenized_less = tokenize_inputs(prompts, less_preferred)\n",
    "\n",
    "    print(\"A4\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ref_w_logit = ref_model(**tokenized_more).logits[:, -1, :]\n",
    "        ref_l_logit = ref_model(**tokenized_less).logits[:, -1, :]\n",
    "\n",
    "    base_w_logit = base_model(**tokenized_more).logits[:, -1, :]\n",
    "    base_l_logit = base_model(**tokenized_less).logits[:, -1, :]\n",
    "\n",
    "    print(\"A5\")\n",
    "\n",
    "    # Compute log probabilities\n",
    "    log_pi_theta_w = F.log_softmax(base_w_logit, dim=-1).mean()\n",
    "    log_pi_theta_l = F.log_softmax(base_l_logit, dim=-1).mean()\n",
    "    log_pi_ref_w = F.log_softmax(ref_w_logit, dim=-1).mean()\n",
    "    log_pi_ref_l = F.log_softmax(ref_l_logit, dim=-1).mean()\n",
    "\n",
    "    # Compute DPO loss\n",
    "    logits_diff = BETA * ((log_pi_theta_w - log_pi_ref_w) - (log_pi_theta_l - log_pi_ref_l))\n",
    "    loss = -torch.log(torch.sigmoid(logits_diff)).mean()\n",
    "\n",
    "    print(\"A6\")\n",
    "    return loss\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(base_model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for _, row in df.iterrows():\n",
    "        prompts = row[\"Question\"]\n",
    "        more_preferred = row[\"More_Prefered\"]\n",
    "        less_preferred = row[\"Less_Prefered\"]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = dpo_loss(base_model, ref_model, prompts, more_preferred, less_preferred)\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(\"A7\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss / len(df)}\")\n",
    "\n",
    "# Save fine-tuned model\n",
    "base_model.save_pretrained(\"gpt2-medium-dpo\")\n",
    "tokenizer.save_pretrained(\"gpt2-medium-dpo\")\n",
    "\n",
    "print(\"Training complete! Fine-tuned model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6pLKONjyCFO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE4bmHohyCFO"
   },
   "outputs": [],
   "source": [
    "#TASK C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T08:39:11.698453Z",
     "iopub.status.busy": "2025-03-01T08:39:11.698076Z",
     "iopub.status.idle": "2025-03-01T08:39:18.373602Z",
     "shell.execute_reply": "2025-03-01T08:39:18.372365Z",
     "shell.execute_reply.started": "2025-03-01T08:39:11.698427Z"
    },
    "id": "okZHU-XnyCFO",
    "outputId": "c4f7945a-f229-47b3-adb3-9adfb4ef1d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T08:50:45.047313Z",
     "iopub.status.busy": "2025-03-01T08:50:45.046814Z",
     "iopub.status.idle": "2025-03-01T08:50:52.714286Z",
     "shell.execute_reply": "2025-03-01T08:50:52.713054Z",
     "shell.execute_reply.started": "2025-03-01T08:50:45.047277Z"
    },
    "id": "Kq-ZPK1jyCFO",
    "outputId": "ad6adab7-8584-4069-d221-91a61750b9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=8b54e2fcda28a9147df301e0161ce8dbd2ca5f2b4092be674161b039bd684ae1\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T08:50:52.716978Z",
     "iopub.status.busy": "2025-03-01T08:50:52.716464Z",
     "iopub.status.idle": "2025-03-01T08:50:55.92046Z",
     "shell.execute_reply": "2025-03-01T08:50:55.918739Z",
     "shell.execute_reply.started": "2025-03-01T08:50:52.71693Z"
    },
    "id": "npECfNe7yCFO",
    "outputId": "9bf1c58f-b2ef-452e-e6fa-3840ec7c5536"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "gpt2-medium-rlhf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/gpt2-medium-rlhf/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67c2ca6f-54b4d2a10d166910279c98ec;9a37ba1e-52f9-4cbb-8fa5-e5b7c6a8d28d)\n\nRepository Not Found for url: https://huggingface.co/gpt2-medium-rlhf/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e4727c24e71c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load fine-tuned models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrlhf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2-medium-rlhf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdpo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2-medium-dpo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2-medium\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: gpt2-medium-rlhf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "# Load BLEU and ROUGE metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Load fine-tuned models\n",
    "rlhf_model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium-rlhf\").to(\"cuda\")\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium-dpo\").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "def generate_response(model, prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\")\n",
    "    output_ids = model.generate(input_ids, max_length=100, do_sample=True, top_k=50, top_p=0.95, temperature=0.7)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Load test dataset\n",
    "test_df = pd.read_csv(\"/kaggle/input/sample1/test_sample.csv\")\n",
    "\n",
    "rlhf_responses = []\n",
    "dpo_responses = []\n",
    "references = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    prompt = row[\"query\"]\n",
    "    reference = row[\"more_preferred\"]\n",
    "\n",
    "    rlhf_responses.append(generate_response(rlhf_model, prompt))\n",
    "    dpo_responses.append(generate_response(dpo_model, prompt))\n",
    "    references.append([reference.split()])  # BLEU expects list of tokenized references\n",
    "\n",
    "# Compute BLEU scores\n",
    "rlhf_bleu = bleu.compute(predictions=[r.split() for r in rlhf_responses], references=references)\n",
    "dpo_bleu = bleu.compute(predictions=[r.split() for r in dpo_responses], references=references)\n",
    "\n",
    "# Compute ROUGE scores (expects raw text, not tokenized lists)\n",
    "rlhf_rouge = rouge.compute(predictions=rlhf_responses, references=[r[0] for r in references])\n",
    "dpo_rouge = rouge.compute(predictions=dpo_responses, references=[r[0] for r in references])\n",
    "\n",
    "# Print results\n",
    "print(f\"RLHF BLEU: {rlhf_bleu}\")\n",
    "print(f\"DPO BLEU: {dpo_bleu}\")\n",
    "print(f\"RLHF ROUGE: {rlhf_rouge}\")\n",
    "print(f\"DPO ROUGE: {dpo_rouge}\")\n",
    "\n",
    "# Summarize findings\n",
    "report = f\"\"\"\n",
    "Performance Comparison: RLHF vs. DPO\n",
    "\n",
    "Sample Efficiency:\n",
    "- RLHF requires reward modeling and PPO training, which is computationally intensive.\n",
    "- DPO uses direct preference optimization, avoiding explicit reward modeling, making it more sample-efficient.\n",
    "\n",
    "Response Quality:\n",
    "- RLHF BLEU: {rlhf_bleu}\n",
    "- DPO BLEU: {dpo_bleu}\n",
    "- RLHF ROUGE: {rlhf_rouge}\n",
    "- DPO ROUGE: {dpo_rouge}\n",
    "\n",
    "Computation Cost:\n",
    "- RLHF involves complex PPO training with reward modeling, leading to higher computational overhead.\n",
    "- DPO is relatively lightweight as it directly optimizes on preferred responses without reinforcement learning.\n",
    "\n",
    "Conclusion:\n",
    "DPO is more efficient and computationally cheaper, while RLHF can provide more controlled response shaping.\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T10:22:13.24736Z",
     "iopub.status.busy": "2025-03-01T10:22:13.246974Z",
     "iopub.status.idle": "2025-03-01T10:22:44.821439Z",
     "shell.execute_reply": "2025-03-01T10:22:44.820241Z",
     "shell.execute_reply.started": "2025-03-01T10:22:13.247327Z"
    },
    "id": "jePYeM8hyCFP",
    "outputId": "cfbf05f0-5db9-452e-eefc-b614300aa385"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ppo_fine_tuned_model were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RLHF model...\n",
      "Evaluating DPO model...\n",
      "\n",
      "Performance Comparison:\n",
      "RLHF BLEU Score: 0.0572\n",
      "RLHF ROUGE Scores: {'rouge-1': 0.17580831408775982, 'rouge-2': 0.010134876724203871, 'rouge-l': 0.09062154834822772}\n",
      "DPO BLEU Score: 0.0563\n",
      "DPO ROUGE Scores: {'rouge-1': 0.22199769053117785, 'rouge-2': 0.014775247953902247, 'rouge-l': 0.11602570539210763}\n",
      "Evaluation complete! Results saved in performance_comparison.txt.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Set device dynamically (use GPU if available, otherwise use CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load fine-tuned models and tokenizer\n",
    "# rlhf_model = AutoModelForCausalLM.from_pretrained(\"ppo_fine_tuned_model\").to(device)\n",
    "rlhf_model = AutoModelForCausalLM.from_pretrained(\"ppo_fine_tuned_model\", ignore_mismatched_sizes=True).to(device)\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium-dpo\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Fix: Set padding token for GPT-2 tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load test dataset from CSV\n",
    "test_dataframe = pd.read_csv(\"/kaggle/input/sample1/test_sample.csv\")\n",
    "\n",
    "# Convert to Hugging Face dataset and then a list\n",
    "test_dataset = Dataset.from_pandas(test_dataframe, preserve_index=False).to_list()\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, tokenizer, dataset):\n",
    "    bleu_scores = []\n",
    "    rouge_scores = {\"rouge-1\": [], \"rouge-2\": [], \"rouge-l\": []}\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "    for entry in dataset:\n",
    "        question = entry[\"Question\"]  # Use \"Question\" as input\n",
    "        reference_answer = entry[\"More_Prefered\"]  # Use \"More_Prefered\" as ground truth\n",
    "\n",
    "        # Tokenize and generate response\n",
    "        input_ids = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        generated_ids = model.generate(\n",
    "            input_ids.input_ids, max_length=100, pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_response = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Compute BLEU score\n",
    "        smoothie = SmoothingFunction().method4\n",
    "        bleu = sentence_bleu([reference_answer.split()], generated_response.split(), smoothing_function=smoothie)\n",
    "        bleu_scores.append(bleu)\n",
    "\n",
    "        # Compute ROUGE scores\n",
    "        rouge_results = scorer.score(reference_answer, generated_response)\n",
    "        rouge_scores[\"rouge-1\"].append(rouge_results[\"rouge1\"].fmeasure)\n",
    "        rouge_scores[\"rouge-2\"].append(rouge_results[\"rouge2\"].fmeasure)\n",
    "        rouge_scores[\"rouge-l\"].append(rouge_results[\"rougeL\"].fmeasure)\n",
    "\n",
    "    # Compute average scores\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_rouge = {k: sum(v) / len(v) for k, v in rouge_scores.items()}\n",
    "\n",
    "    return avg_bleu, avg_rouge\n",
    "\n",
    "# Evaluate both models\n",
    "print(\"Evaluating RLHF model...\")\n",
    "rlhf_bleu, rlhf_rouge = evaluate_model(rlhf_model, tokenizer, test_dataset)\n",
    "\n",
    "print(\"Evaluating DPO model...\")\n",
    "dpo_bleu, dpo_rouge = evaluate_model(dpo_model, tokenizer, test_dataset)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(f\"RLHF BLEU Score: {rlhf_bleu:.4f}\")\n",
    "print(f\"RLHF ROUGE Scores: {rlhf_rouge}\")\n",
    "\n",
    "print(f\"DPO BLEU Score: {dpo_bleu:.4f}\")\n",
    "print(f\"DPO ROUGE Scores: {dpo_rouge}\")\n",
    "\n",
    "# Save results to a file\n",
    "with open(\"performance_comparison.txt\", \"w\") as f:\n",
    "    f.write(\"Performance Comparison:\\n\")\n",
    "    f.write(f\"RLHF BLEU Score: {rlhf_bleu:.4f}\\n\")\n",
    "    f.write(f\"RLHF ROUGE Scores: {rlhf_rouge}\\n\")\n",
    "    f.write(f\"DPO BLEU Score: {dpo_bleu:.4f}\\n\")\n",
    "    f.write(f\"DPO ROUGE Scores: {dpo_rouge}\\n\")\n",
    "\n",
    "print(\"Evaluation complete! Results saved in performance_comparison.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZ2Y0U7ryCFP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GenAI_TaskA",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6644875,
     "sourceId": 10719895,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
